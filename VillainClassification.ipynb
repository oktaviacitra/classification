{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VillainClassification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQmfSyhfsSOdN8aVOgNqk8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oktaviacitra/classification/blob/main/VillainClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ioK88NuBHUM",
        "outputId": "ed957e3a-117d-42c1-a7e8-86f25fb63fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "origin_path = \"/content/drive\"\n",
        "drive.mount(origin_path)\n",
        "\n",
        "folder_path = origin_path + \"/MyDrive/Learning Journey/Villain Data/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = [\"Vader\", \"Green Goblin\", \"Joker\", \"Thanos\", \"Venom\"]\n",
        "image_files = [ (folder_path + label + \"/\" + label + \" \" + str(i) + \".jpg\") for i in range(1, 21) for label in class_labels]\n",
        "len(image_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRH6WbiEELaw",
        "outputId": "13d18791-5d15-46c0-ef62-611002e79d21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def preprocessing_image(path, target):\n",
        "    img = Image.open(path)\n",
        "\n",
        "    # crop central\n",
        "    width, height = img.size\n",
        "    new_width = new_height = width\n",
        "    left = (width - new_width)/2\n",
        "    top = (height - new_height)/2\n",
        "    right = (width + new_width)/2\n",
        "    bottom = (height + new_height)/2\n",
        "    img = img.crop((left, top, right, bottom))\n",
        "\n",
        "    # convert to array of rgb\n",
        "    img = img.resize(target)\n",
        "    img = img.convert('RGB')\n",
        "    x = image.img_to_array(img)\n",
        "    x = x[:, :, :3]\n",
        "    x = np.true_divide(x, 255)\n",
        "    return x"
      ],
      "metadata": {
        "id": "pK1ZNXe5GcH1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X = np.asarray([preprocessing_image(image_file, (64,64)) for image_file in image_files])\n",
        "\n",
        "y = [ label for i in range(1, 21) for label in class_labels]\n",
        "le = LabelEncoder()\n",
        "le.fit(y)\n",
        "y = le.transform(y)\n",
        "\n",
        "\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICaKWuQCTPF3",
        "outputId": "a60c0da0-7a2a-4108-8aeb-bee15a9a1ef4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 64, 64, 3), (100,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
        "X_train.shape, X_test.shape, X_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEFRI9oUyreI",
        "outputId": "454dcd7f-bde6-47ab-835a-b0a4cde3f285"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((70, 64, 64, 3), (15, 64, 64, 3), (15, 64, 64, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAwfaDnJ0jsy",
        "outputId": "8968ac17-08fb-41da-b502-3415b3036600"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▍                             | 10 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 20 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 30 kB 17.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 40 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 61 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 71 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 81 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 92 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 102 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 112 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 122 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 133 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 135 kB 8.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Input, Model, regularizers\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, Activation, Flatten, Dense, GlobalAveragePooling2D, GlobalMaxPooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "def model_builder(hp):\n",
        "  inputs = Input(shape=(64, 64, 3))\n",
        "  x = Conv2D(filters = hp.Int('filters', min_value=64, max_value=1024, step = 32),\n",
        "             kernel_size = hp.Int('kernel_size', 3, 5),\n",
        "             padding=\"same\",\n",
        "             activation='relu',\n",
        "             dilation_rate=2,\n",
        "             kernel_initializer = \"he_normal\",\n",
        "             kernel_regularizer=regularizers.l2(0.001),\n",
        "             name=\"conv2d\")(inputs)\n",
        "\n",
        "  if hp.Choice('pooling', ['max', 'avg']) == 'max':\n",
        "    x = MaxPooling2D(name=\"maxpool2d\")(x)\n",
        "  else:\n",
        "    x = AveragePooling2D(name=\"averagepool2d\")(x)\n",
        "\n",
        "  x = BatchNormalization(name=\"batchnorm\")(x)\n",
        "  x = Dropout(0.1, name=\"dropout\")(x)\n",
        "\n",
        "  if hp.Choice('pooling', ['max', 'avg']) == 'max':\n",
        "    x = GlobalMaxPooling2D(name='globalmaxpool')(x)\n",
        "  else:\n",
        "    x = GlobalAveragePooling2D(name='globalaveragepool')(x)\n",
        "\n",
        "  x = Dense(units=hp.Int('units_1', min_value=128, max_value=512, step=32),\n",
        "            activation='relu',\n",
        "            name='fully_connected')(x)\n",
        "  outputs = Dense(5, activation='softmax', name='prediction')(x)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "  optimizer = Adam(learning_rate=learning_rate) if hp.Choice('optimizer', ['adam', 'sgd']) == 'adam' else SGD(learning_rate=learning_rate)\n",
        "  \n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "xK4_t7O7k0Tn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "tuner = kt.Hyperband(hypermodel = model_builder,\n",
        "                             objective = 'val_loss',\n",
        "                             max_epochs = 10,\n",
        "                             factor = 3,\n",
        "                             directory = folder_path + '/results_dir',\n",
        "                             project_name = 'villain')\n",
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urYg998ax9RK",
        "outputId": "915d64fd-e446-4cc0-e163-41edb40483b3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 6\n",
            "filters (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 1024, 'step': 32, 'sampling': None}\n",
            "kernel_size (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 5, 'step': 1, 'sampling': None}\n",
            "pooling (Choice)\n",
            "{'default': 'max', 'conditions': [], 'values': ['max', 'avg'], 'ordered': False}\n",
            "units_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 128, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
            "optimizer (Choice)\n",
            "{'default': 'adam', 'conditions': [], 'values': ['adam', 'sgd'], 'ordered': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "best_weight = ModelCheckpoint(folder_path + \"tuner/{epoch:02d}-{val_loss:.4f}.h5\",\n",
        "                              monitor=\"val_loss\",\n",
        "                              mode=\"min\",\n",
        "                              save_best_only=True,\n",
        "                              verbose=1)\n",
        "stop_early = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=20,\n",
        "             validation_data=(X_val, y_val),\n",
        "             callbacks=[stop_early, best_weight],\n",
        "             verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ej7cz6ayWcE",
        "outputId": "974d7f44-be18-4b78-f0db-eb01d3934d1a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 04s]\n",
            "val_loss: 2.48443341255188\n",
            "\n",
            "Best val_loss So Far: 1.9182846546173096\n",
            "Total elapsed time: 00h 01m 13s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(folder_path + \"tuner/06-1.9183.h5\")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaSTYe3FAWfO",
        "outputId": "52dd2e53-7bd4-4c01-a307-0d2f3421befe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 64, 64, 160)       12160     \n",
            "                                                                 \n",
            " averagepool2d (AveragePooli  (None, 32, 32, 160)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batchnorm (BatchNormalizati  (None, 32, 32, 160)      640       \n",
            " on)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 32, 160)       0         \n",
            "                                                                 \n",
            " globalaveragepool (GlobalAv  (None, 160)              0         \n",
            " eragePooling2D)                                                 \n",
            "                                                                 \n",
            " fully_connected (Dense)     (None, 224)               36064     \n",
            "                                                                 \n",
            " prediction (Dense)          (None, 5)                 1125      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 49,989\n",
            "Trainable params: 49,669\n",
            "Non-trainable params: 320\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "callbacks = [EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1),\n",
        "             ReduceLROnPlateau(monitor = 'val_loss', factor=0.1, patience=2, verbose=1),\n",
        "             ModelCheckpoint(\"/kaggle/working/s{epoch:02d}-{val_loss:.4f}.h5\", monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)]\n",
        "history = model.fit(X_train, y_train, epochs=200,\n",
        "                    validation_data=(X_val, y_val), verbose=1,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0SjxqofA2SU",
        "outputId": "5c5f8d23-84ce-4ad4-92cb-76f483a56100"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.9809 - accuracy: 0.0625\n",
            "Epoch 1: val_loss improved from inf to 1.91848, saving model to /kaggle/working/s01-1.9185.h5\n",
            "3/3 [==============================] - 0s 110ms/step - loss: 1.9640 - accuracy: 0.1857 - val_loss: 1.9185 - val_accuracy: 0.2667 - lr: 1.0000e-04\n",
            "Epoch 2/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.8841 - accuracy: 0.3125\n",
            "Epoch 2: val_loss did not improve from 1.91848\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.9571 - accuracy: 0.2000 - val_loss: 1.9196 - val_accuracy: 0.1333 - lr: 1.0000e-04\n",
            "Epoch 3/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.9202 - accuracy: 0.2812\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "\n",
            "Epoch 3: val_loss did not improve from 1.91848\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.9335 - accuracy: 0.2429 - val_loss: 1.9210 - val_accuracy: 0.2000 - lr: 1.0000e-04\n",
            "Epoch 4/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.9491 - accuracy: 0.2500\n",
            "Epoch 4: val_loss did not improve from 1.91848\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.9224 - accuracy: 0.3000 - val_loss: 1.9205 - val_accuracy: 0.2000 - lr: 1.0000e-05\n",
            "Epoch 4: early stopping\n"
          ]
        }
      ]
    }
  ]
}