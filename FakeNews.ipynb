{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwjTkO0UmlxA3ZofJkKgJj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oktaviacitra/classification/blob/main/FakeNews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOR3MCRP5-lZ",
        "outputId": "28001030-f844-4417-d2a8-041759d25111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "origin_path = \"/content/drive\"\n",
        "drive.mount(origin_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "folder_path = origin_path + \"/MyDrive/Learning Journey/Fake News\"\n",
        "dataset_path = folder_path + \"/dataset.csv\"\n",
        "dataframe = pd.read_csv(dataset_path)\n",
        "dataframe.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "H0qzf6Cs73EI",
        "outputId": "8b6c0bd2-adc3-4212-d47f-d6dae66ffce9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 author                      published  \\\n",
              "0     Barracuda Brigade  2016-10-26T21:41:00.000+03:00   \n",
              "1  reasoning with facts  2016-10-29T08:47:11.259+03:00   \n",
              "2     Barracuda Brigade  2016-10-31T01:41:49.479+02:00   \n",
              "\n",
              "                                               title  \\\n",
              "0  muslims busted they stole millions in govt ben...   \n",
              "1  re why did attorney general loretta lynch plea...   \n",
              "2  breaking weiner cooperating with fbi on hillar...   \n",
              "\n",
              "                                                text language  \\\n",
              "0  print they should pay all the back all the mon...  english   \n",
              "1  why did attorney general loretta lynch plead t...  english   \n",
              "2  red state  \\nfox news sunday reported this mor...  english   \n",
              "\n",
              "              site_url                                       main_img_url  \\\n",
              "0  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
              "1  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
              "2  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
              "\n",
              "   type label                            title_without_stopwords  \\\n",
              "0  bias  Real        muslims busted stole millions govt benefits   \n",
              "1  bias  Real         attorney general loretta lynch plead fifth   \n",
              "2  bias  Real  breaking weiner cooperating fbi hillary email ...   \n",
              "\n",
              "                              text_without_stopwords  hasImage  \n",
              "0  print pay back money plus interest entire fami...       1.0  \n",
              "1  attorney general loretta lynch plead fifth bar...       1.0  \n",
              "2  red state fox news sunday reported morning ant...       1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94d03cca-5004-491c-8ed6-8e8239e68a38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>published</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>site_url</th>\n",
              "      <th>main_img_url</th>\n",
              "      <th>type</th>\n",
              "      <th>label</th>\n",
              "      <th>title_without_stopwords</th>\n",
              "      <th>text_without_stopwords</th>\n",
              "      <th>hasImage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Barracuda Brigade</td>\n",
              "      <td>2016-10-26T21:41:00.000+03:00</td>\n",
              "      <td>muslims busted they stole millions in govt ben...</td>\n",
              "      <td>print they should pay all the back all the mon...</td>\n",
              "      <td>english</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>bias</td>\n",
              "      <td>Real</td>\n",
              "      <td>muslims busted stole millions govt benefits</td>\n",
              "      <td>print pay back money plus interest entire fami...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>reasoning with facts</td>\n",
              "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
              "      <td>re why did attorney general loretta lynch plea...</td>\n",
              "      <td>why did attorney general loretta lynch plead t...</td>\n",
              "      <td>english</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>bias</td>\n",
              "      <td>Real</td>\n",
              "      <td>attorney general loretta lynch plead fifth</td>\n",
              "      <td>attorney general loretta lynch plead fifth bar...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Barracuda Brigade</td>\n",
              "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
              "      <td>breaking weiner cooperating with fbi on hillar...</td>\n",
              "      <td>red state  \\nfox news sunday reported this mor...</td>\n",
              "      <td>english</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>bias</td>\n",
              "      <td>Real</td>\n",
              "      <td>breaking weiner cooperating fbi hillary email ...</td>\n",
              "      <td>red state fox news sunday reported morning ant...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94d03cca-5004-491c-8ed6-8e8239e68a38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94d03cca-5004-491c-8ed6-8e8239e68a38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94d03cca-5004-491c-8ed6-8e8239e68a38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs0zDWe4vGdb",
        "outputId": "83c36b81-06b9-4741-f4d5-44e54dc3d51f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "author                      0\n",
              "published                   0\n",
              "title                       0\n",
              "text                       46\n",
              "language                    1\n",
              "site_url                    1\n",
              "main_img_url                1\n",
              "type                        1\n",
              "label                       1\n",
              "title_without_stopwords     2\n",
              "text_without_stopwords     50\n",
              "hasImage                    1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataframe['text']\n",
        "y = dataframe['label']"
      ],
      "metadata": {
        "id": "SxdpoNYYR1-D"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_indices = dataframe[dataframe['text'].isna()].index.tolist()"
      ],
      "metadata": {
        "id": "KEsKCE5bYiZ-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.dropna()\n",
        "y = y.drop(y_indices)"
      ],
      "metadata": {
        "id": "CVOP9CSbSVdq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVPtpC01SYTa",
        "outputId": "2d51af43-8d26-4541-a862-0d3c445accd2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.to_list()\n",
        "y = y.to_list()"
      ],
      "metadata": {
        "id": "OOeLHyedUb4e"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "documents = []\n",
        "stemmer = WordNetLemmatizer()\n",
        "\n",
        "for sen in range(0, len(X)):\n",
        "    # Remove all the special characters\n",
        "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
        "    \n",
        "    # remove all single characters\n",
        "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
        "    \n",
        "    # Remove single characters from the start\n",
        "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
        "    \n",
        "    # Substituting multiple spaces with single space\n",
        "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "    \n",
        "    # Removing prefixed 'b'\n",
        "    document = re.sub(r'^b\\s+', '', document)\n",
        "    \n",
        "    # Converting to Lowercase\n",
        "    document = document.lower()\n",
        "    \n",
        "    # Lemmatization\n",
        "    document = document.split()\n",
        "\n",
        "    document = [stemmer.lemmatize(word) for word in document]\n",
        "    document = ' '.join(document)\n",
        "    \n",
        "    documents.append(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwQOR16dUULx",
        "outputId": "d1e7cade-cf38-49cf-f7dc-ac1174b60132"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
        "X = vectorizer.fit_transform(documents).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6ciBKra9Bx3",
        "outputId": "d3cb093f-3999-48d2-d0af-e86470c4f743"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "sKjuwu0qX1r5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://stackabuse.com/text-classification-with-python-and-scikit-learn/"
      ],
      "metadata": {
        "id": "gVRYvcsXUiRU"
      }
    }
  ]
}